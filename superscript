#!/bin/bash
# This was a mistake. 



# global variables
VERSION="1.1.7"
DATETIME=$(date +"%Y_%m_%d__%H_%M_%S")


# TODO: add glocal LOG variable and print to that as well as to console
print() {
	if [ "$1" == "-e" ]
	then
		printf "Error: ${*:2}"
	else
		printf "${*:2}"
	fi
}



# archive [source dir] [backup dir] [number of backups to keep]
# TODO: dont delete unrelated files in backup dir
archive() {
	local NUM2KEEP=5
	# tar and compress (multithreaded) all files in $1 except $2
	tar -cf - --exclude=$2 $1 | xz -9 --threads=0 --memlimit=50% -c - > $2/$DATETIME.tar.xz

        # if there are now too many archives, delete the oldest one(s)
	if (( $(ls $2 | wc -l) > $NUM2KEEP))
        then
                # list files in $2 directory (one per line), newest first
		# remove the first (newest) $3 files from the list.
                # delete the items remaining in the list.
		ls -1tr $2 | head -n -$NUM2KEEP | xargs -t -I file rm $2/file
        fi
}




rsync() {
	if (( $# < 2 )); then
		print -e "This command needs at least two arguments\n"
		"Use: superscript rsync [source] [destination]\n"
		"Result: rsync -r --size-only --delete -vh --progress [source] [destination]"
	fi
	command rsync -r --size-only --delete -vh --progress $1 $2
}




# backs up to gdrive crypt via rclone
# $1 : source directory
# $2 : destination directory
# TODO: add -f (force) option to skip empty directory check
# TODO: add -d (destination-directory) option to specify dest. dir.
# TODO: add -t (tar) option to tar source directory before upload
# TODO: add a check to see if rclone is installed and configured
rclone() {
	local tar=false
	if [ $1 = '-t' ]; then
		 tar=true
	fi

	local SOURCE_DIR=${@: -1}
	local DEST_DIR=$(basename $SOURCE_DIR)

	local LOG=/tmp/rclone_"$DEST_DIR"_"$DATETIME".log


	if [ -z "$(ls -A $SOURCE_DIR)" ] # if directory is empty
	then
		print -e "\"$SOURCE_DIR\" is empty or does not exist.\nSkipping sync."
		exit 1
	fi

	#TODO: pipe output of tar and xz to log
	if [ $tar = true ] ; then
		print "Warning: tarballing $SOURCE_DIR. Please make sure there is enough space in /tmp"
		tar -cf - $SOURCE_DIR | xz -v9 --threads=0 --memlimit=50% -c - > /vault/temp/$DEST_DIR.tar.xz
		SOURCE_DIR=/vault/temp/$DEST_DIR.tar.xz
	fi

	print "Backing up $SOURCE_DIR to encrypted-gdrive:$DEST_DIR"
	# Put the rclone job in a GNU parallel semaphore queue. only one rclone command will run at a time.
        # sem will exit when its respective rclone command exits.
	command /usr/bin/rclone sync --drive-stop-on-upload-limit --delete-after --max-backlog=100000 --transfers 2 -v --stats 10s $SOURCE_DIR encrypted-gdrive:$DEST_DIR &>> $LOG
	local EXITCODE1=$?

	# Cleanup
	if [ $tar = true]; then
		rm /vault/temp/$DEST_DIR.tar.xz
	fi

	# If rclone exits with code 7 (gdrive limit reached),
	if [ $EXITCODE1 == 7 ]; then
		local ERROR="Google Drive daily upload limit reached."
		print -e $ERROR
		cat $ERROR > $LOG
		exit 1
	# Else if rclone exits with any other error
	elif [ $EXITCODE1 != 0 ]; then
		print -e "rclone failed to sync $SOURCE_DIR with exit code $EXITCODE1"
		cat $LOG >&2
		exit 1
	fi
}




rclonecheck() {
	local SOURCE_DIR=$1
	local DEST_DIR=$(basename $1)

	if [ -z "$(ls -A $SOURCE_DIR)" ] # if directory is empty
	then
		print -e "\"$SOURCE_DIR\" is empty or does not exist.\nSkipping sync."
		exit 1
	fi

	# If no errors, check the remote to ensure sync was sucessful
	command /usr/bin/rclone cryptcheck $SOURCE_DIR encrypted-gdrive:$DEST_DIR &> /tmp/rclone_cryptcheck_$DEST_DIR.log
	local EXITCODE2=$?
	if [ $EXITCODE2 -ne 0 ]; then
		print -e "sync failed.\ncryptcheck found missing files in remote:"
		cat /tmp/rclone_cryptcheck_$DEST_DIR.log >&2
	fi
	exit 0
}




lvsnap() {
	local usage="lvsnap <volume_group/logical_volume> [number of snapshot to keep]"
	local num2keep=7

	if [ "$1" == "-h" ]; then
		print "$usage"
	fi
	if (( $# > 1 )); then
		num2keep=$2
	fi
	
	local vg="${1%/*}"
	local origin="${1#*/}"

	local snapname=$origin"_snap_$DATETIME"
	lvcreate -s $1 --name $snapname

	if (( $(lvs -o lv_name,lv_time,origin | tail -n +2 | awk 'x$5' | wc -l) > $num2keep ))
	then
		lvs -o lv_name,lv_time,origin | tail -n +2 | awk 'x$5' | grep $origin | sort -k2 | head -n -$num2keep | awk '{print $1}' | xargs -I lv lvremove $vg/lv
	fi

	
}




#lvrestore(){
#}




# zfssnapshot [dataset] [number of snapshots to keep]
zfssnapshot() {
	local num2keep=10
	if (( $# > 1 )); then
		num2keep=$2
	fi

	snapname="snap_$DATETIME"
	zfs snapshot $1@$snapname

	if (( $(zfs list -t snapshot | grep $1 | wc -l) > $num2keep))
	then	
	zfs list -t snapshot | grep $1 | awk '{print $1}' | head -n -$num2keep | xargs -I snap zfs destroy snap
	fi
}




#number
vmsnapshot() {
	if (( $# < 1 )); then
		print "Error: this command requires at least one argument"
		print "usage: superscript snapshot [vmid] [# snapshots to keep]"
		return
	fi

	local VMID=$1
	local SNAPNAME=$(/usr/sbin/qm config $VMID | grep '^name:' | awk '{print $2}')
	local NUM2KEEP=6 # By default keep 5 snapshots

	# Override default value if option is provided
	if (( $# >= 2 )); then
		local NUM2KEEP=$($2 + 1)
	fi

        # Take a new snapshot
        qm snapshot $VMID "$SNAPNAME"_"$DATETIME" --vmstate true

        #if there are now too many snapshots, delete the oldest one(s)
        local SNAP_COUNT=$(/usr/sbin/qm listsnapshot $VMID | awk '{print $2}' | wc -l)
        if [ $SNAP_COUNT -gt $NUM2KEEP ]; then
               qm listsnapshot $VMID | awk '{print $2}' | head -n -$NUM2KEEP | xargs -I snapname qm delsnapshot $VMID snapname
        fi
}




# When adding a script above, be sure to add its option to the switch below!
case "${1:-}" in
	-v|version)
	printf "Superscript version: $VERSION\n"
	;;

	archive)
	archive "${@:2}"
	;;

	rclone)
	rclone "${@:2}"
	;;

	rclonecheck)
	rclonecheck "${@:2}"
	;;

	rsync)
	rsync "${@:2}"
	;;

	lvsnap)
	lvsnap "${@:2}"
	;;

	zfssnapshot)
	zfssnapshot "${@:2}"
	;;

	vmsnapshot)
	vmsnapshot "${@:2}"
	;;
esac







