#!/usr/bin/env python3

version = "2.4.1b"

# TODO: cleanup within refresh function
# does canceling a transfer (refresh) leave garbage snapshots on target?

# TODO: make sure ssh has access to destination host
# TODO: implement resuming

# Low Prior
# TODO: add ssh source support (if zfs supports it)

import argparse
import atexit
from datetime import datetime
import fnmatch
from shutil import which
import subprocess
import sys


usage = f"""
zsync version: {version}
Uses ZFS send/receive to sync a ZFS filesystem between source and destination\n

Usage: zsync [OPTION] <source dataset> <destination dataset>
 or    zsync <-s | -ssh> <source dataset> [<USER>@]<HOST>:<destination dataset>
"""


bookmark_suffix = "zsync_incremental"
date_time = datetime.now().isoformat(timespec='seconds')
ssh = False
verbose = False
forse = False
quiet = not sys.stdout.isatty()



def main():
    parser = argparse.ArgumentParser(description=usage, formatter_class=argparse.RawDescriptionHelpFormatter)
    parser.add_argument("source_dataset")
    parser.add_argument("destination_dataset")

    parser.add_argument(
        "-s",
        "--ssh",
        dest="ssh",
        action="store_true",
        help="Send stream to a destination over ssh",
    )
    parser.add_argument(
        "-v",
        dest="verbose",
        action="store_true",
        help="Enable verbose output"
    )
    parser.add_argument(
        "-f",
        "--full",
        "--force",
        dest="force",
        action="store_true",
        help="Perform a full backup if differential information is missing"
        + " for destination (overwrites existing data on destination)",
    )
    parser.add_argument(
        "--version",
        dest="version_query",
        action="version",
        version=f"zsync version: {version}",
        help="Print zsync version",
    )

    args = parser.parse_args()

    source = args.source_dataset
    destination = args.destination_dataset
    global ssh
    ssh = args.ssh
    global verbose
    verbose = args.verbose
    global force
    force = args.force
    dest_host = None
    ssh_cmd = ""

    # Check that required programs exist on destination machine
    if which("zfs") is None:
        log("Error: zfs: command not found.")
        exit(2)
    # TODO: check for zfs command on target host (ssh)

    # check that source dataset exists
    if source not in execute("zfs list"):
        log(f"Error: source dataset '{source}' does not exist")
        exit(2)

    if ssh:
        dest_host = destination.split(":")[0]
        destination = destination.split(":")[1]
        ssh_cmd = f"ssh {dest_host} "

    try:
        # check that destination dataset(s) exist
        pools_to_sync = check_destination(dest_host, destination)
        dest_path = destination.split("/", 1)[1]  # destination without pool
        snap_name = f"{source}@backup_{date_time}"
        atexit.register(export, pools_to_sync, dest_host)

        vlog(f"Snapshotting source: '{snap_name}'")
        execute(f"zfs snapshot {snap_name}")
        atexit.register(delete_snapshot, snap_name)

        vlog(f"Syncing to pools: {pools_to_sync} - Remote host: '{dest_host}'")
        for dest_pool in pools_to_sync:
            destination = f"{dest_pool}/{dest_path}"
            formatted_dest = destination.replace("/", "_")
            bookmark_name = f"{source}#{formatted_dest}-{bookmark_suffix}"

            log(f"\nSyncing destination '{destination}'")
            vlog(f"Bookmark name: '{bookmark_name}'")

            # if last bookmark and destination dataset exist
            bookmark_exists = bookmark_name in execute(f"zfs list -t bookmark {source}")
            dest_dataset_exists = destination in execute(ssh_cmd + f"zfs list -r {dest_pool} -o name")

            if dest_dataset_exists:
                if bookmark_exists:
                    rc = refresh(source, dest_host, destination, snap_name, bookmark_name)
                # elif: # TODO - lp: see if a snapshot '@backup' exists, see if it will work
                # can use zfs diff to compare dest snapshot to source snapshots
                else:
                    if not force:
                        elog(f"Error: dataset '{destination}' exists but no differential information"
                            + " is available (bookmark missing)\nSupply -f to force overwrite")
                        continue
                    else:
                        log(f"Dataset '{destination}' exists but no differential information"
                            + " is available (bookmark missing)\nWill overwrite")
                        vlog(f"Destroying destination dataset '{destination}'")
                        execute(ssh_cmd + f"zfs destroy -r {destination}")
                        rc = init(source, dest_host, destination, snap_name, bookmark_name)
            else:
                if bookmark_exists:
                    log(f"Bookmark '{bookmark_name}' exists but its dataset is missing")
                    log("Destroying bookmark")
                    execute(ssh_cmd + f"zfs destroy {bookmark_name}")

                rc = init(source, dest_host, destination, snap_name, bookmark_name)

            # RC: 0 success, 1 failure, 2 failure converting snapshot
            if rc == 2:
                atexit.unregister(delete_snapshot)

    except KeyboardInterrupt:
        log("Terminating zsync")
        log("Cleanup up")
        raise SystemExit


def check_destination(dest_host, destination):
    wildcards = ["?", "*"]

    ssh_cmd = f"ssh {dest_host} " if ssh else ""

    imported = [pool for pool in execute(ssh_cmd + "zpool list -o name").splitlines() if pool != "NAME"]
    exported = [pool.split(": ")[1] for pool in execute(ssh_cmd + "zpool import").splitlines() if "pool:" in pool]

    dest_pool = destination.split("/")[0]

    if [wildcard in dest_pool for wildcard in wildcards]:
        vlog("Checking wildcards")

        im_match = fnmatch.filter(imported, dest_pool)
        ex_match = fnmatch.filter(exported, dest_pool)

        for pool in im_match:
            log(f"Note: zpool '{pool}' was already mounted")

        for pool in ex_match:
            vlog(f"Importing pool '{pool}'")
            rc = execute(ssh_cmd + f"zpool import {pool}", return_rc=True)
            if rc == 0:
                im_match.append(pool)

        if im_match:
            return im_match
        else:
            elog(f"Error: no valid substitutions for '{dest_pool}' exist")

    else:  # not checking wildcard
        if dest_pool in imported:
            log(f"Note: zpool '{dest_pool}' was already mounted")
            return [dest_pool]
        elif dest_pool in exported:
            vlog(f"Importing pool '{pool}'")
            rc = execute(ssh_cmd + f"zpool import {pool}", return_rc=True)

            if rc == 0:
                return [dest_pool]
            else:
                elog(f"Error: destination pool '{dest_pool}' does not exist")

    if ":" in destination:
        log("Did you mean to specify ssh (-s)?")
    exit(2)


def init(source, dest_host, destination, snap_name, bookmark_name):
    ssh_cmd = f"ssh {dest_host} " if ssh else ""

    log(f"Performing full backup of {source}")

    log(f"Sending '{snap_name}' to '{destination}'")
    success = send_recv(snap_name, None, destination, dest_host)

    # if the send command completely sucessfully
    if success:
        # if bookmark already exists, delete it
        if bookmark_name in execute(f"zfs list -t bookmark {source}"):
            execute(f"zfs destroy {bookmark_name}")

        # convert the source snapshot to a bookmark for future incremental sends
        rc = execute(f"zfs bookmark {snap_name} {bookmark_name}", return_rc=True)

        # if snapshot => bookmark conversion succeeded
        if rc == 0:
            return 0
        else:
            elog(f"Error converting snapshot '{snap_name}' into bookmark '{bookmark_name}'")
            return 2
    else:  # if the command failed, delete the orphaned snapshot
        elog(f"Error: ZFS send failed")
        return 1


def refresh(source, dest_host, destination, snap_name, bookmark_name):
    ssh_cmd = f"ssh {dest_host} " if ssh else ""

    log(f"Sending incremental snapshot '{snap_name}' to '{destination}'")
    success = send_recv(snap_name, bookmark_name, destination, dest_host)

    # if send command failed, likely source/dest are out of sync or bookmark wasn't created
    if not success and force:
        # roll back each destination snapshot and attemp to sync
        # the likelihood that this succeeds is low, but it's cheaper than a full backup
        snaplist = list_snapshots(destination)

        if snaplist:
            for dest_snap in snaplist:
                snap_suffix = dest_snap.split("@")[1]
                source_snap = f"{source}@{snap_suffix}"
                if snap_suffix in execute(f"zfs list -t snapshot {source}"):
                    log(f"Rolling back '{destination}' to snapshot '{dest_snap}'")
                    execute(ssh_cmd + f"zfs rollback -rf {dest_snap}")
                    log(f"Sending incremental snapshot '{snap_name}' to '{destination}'")
                    success = send_recv(snap_name, source_snap, destination, dest_host)
                    if success:
                        break

    # if that didn't work, try full backup
    if not success:
        elog("Error: ZFS incremental send failed")
        if force:
            log("Attempting full backup")
            vlog(f"Destroying destination dataset '{destination}'")
            execute(ssh_cmd + f"zfs destroy -r {destination}")
            result = init(source, dest_host, destination, snap_name, bookmark_name)
            return result
        else:
            log("Supply -f to force overwrite (full backup)")
            return 1

    # if success, clean up
    if bookmark_name in execute(f"zfs list -t bookmark {source}"):
        vlog("Deleting old bookmark")
        execute(f"zfs destroy {bookmark_name}")

    # only save most recent snapshot on destination
    purgelist = list_snapshots(destination)
    if purgelist:
        del purgelist[0]  # remove latest snapshot from list
        for snap in purgelist:  # delete snapshots remaining on list
            vlog(f"Destroying snapshot on destination: {snap}")
            execute(ssh_cmd + f"zfs destroy {snap}")

    vlog(f"Converting source snapshot into bookmark: {snap_name} -> {bookmark_name}")
    rc = execute(f"zfs bookmark {snap_name} {bookmark_name}", return_rc=True)

    # if snapshot => bookmark conversion succeeded
    if rc == 0:
        return 0
    else:
        elog(f"Error converting snapshot '{snap_name}' into bookmark")
        return 2


def execute(command, return_rc=False):
    cmdarr = command.split()
    result = subprocess.run(cmdarr, text=True, capture_output=True)

    if return_rc:
        return result.returncode
    else:
        return result.stdout


def send_recv(snap_name, bookmark_name, destination, dest_host):
    if pvmissing := which("pv") is None:
        elog("Error: pv: command not found. Cannot print status")

    ssh_cmd = f"ssh {dest_host} " if dest_host is not None else ""

    if bookmark_name is not None:
        cmd1 = f"zfs send -wi {bookmark_name} {snap_name}".split()
        cmd2 = (ssh_cmd + f"zfs recv -vFu {destination}").split()
    else:
        cmd1 = f"zfs send -w {snap_name}".split()
        cmd2 = (ssh_cmd + f"zfs recv -vFu {destination}").split()

    p1 = subprocess.Popen(cmd1, stdout=subprocess.PIPE)

    if not quiet and not pvmissing:
        p2 = subprocess.Popen(
            ["pv", "-f"],
            stdin=p1.stdout,
            stdout=subprocess.PIPE,
            stderr=sys.stdout,
        )  # universal_newlines=True,
    else:
        p2 = p1

    # this one doesn't like to die even when ran in native bash shell
    p3 = subprocess.Popen(cmd2, stdin=p2.stdout, stdout=subprocess.PIPE)

    p3.wait()  # wait on p3 because p1 may never return in the event of recv failure

    if p3.returncode != 0:
        vlog(f"Process returncode: {p3.returncode}")

    return p3.returncode == 0


def list_snapshots(dataset):
    snaplist = execute(f"zfs list -t snapshot -s creation -o name {dataset}").splitlines()
    if snaplist:
        del snaplist[0]  # remove header from list
        snaplist.reverse()  # most recent first
    return snaplist  # trim garbage


def log(message):
    if not quiet:
        print(message)


def vlog(message):
    if verbose and not quiet:
        print(message)


def elog(message):
    print(f"{date_time} {message}")


## Cleanup Functions #########


def export(pool_list, dest_host):
    ssh_cmd = f"ssh {dest_host} " if dest_host is not None else ""
    logappend = f" on host '{dest_host}'" if dest_host is not None else ""
    for pool in pool_list:
        vlog(f"Exporting pool '{pool}'" + logappend)
        execute(ssh_cmd + f"zpool export {pool}")


def delete_snapshot(snap_name):
    vlog(f"Deleting source snapshot '{snap_name}'")
    execute(f"zfs destroy {snap_name}")


main()
